{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# Working with Small Datasets"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Augmentation\n",
   "id": "2a56c4e760bdfd31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:14:08.284677Z",
     "start_time": "2025-11-11T18:14:08.277734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf, keras\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)"
   ],
   "id": "28766d55a92f53bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.19.0\n",
      "Keras: 3.10.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T18:19:09.760505Z",
     "start_time": "2025-11-11T18:19:05.913876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# creates a data generator object that transforms images\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# pick an image to transform\n",
    "test_ima  = train_images[20]\n",
    "img = image.img_to_array(test_ima) # convert image to numpy array\n",
    "img = img.reshape((1,) + img.shape) # reshape image\n",
    "\n",
    "i = 0\n",
    "\n",
    "# this loop runs forever until we break, saving images to current directory with specified prefix\n",
    "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):\n",
    "    plt.figure(i)\n",
    "    plot = plt.imshow(image.img_to_array(batch[0]))\n",
    "    i +=1\n",
    "    if i > 4: # show 4 images\n",
    "        break\n",
    "plt.show()"
   ],
   "id": "b47a28952971a6fa",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/opt/anaconda3/lib/python3.12/site-packages/keras/preprocessing/image/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m image\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageDataGenerator\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# creates a data generator object that transforms images\u001B[39;00m\n\u001B[1;32m      9\u001B[0m datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(\n\u001B[1;32m     10\u001B[0m     rotation_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m,\n\u001B[1;32m     11\u001B[0m     width_shift_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     fill_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnearest\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     17\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/opt/anaconda3/lib/python3.12/site-packages/keras/preprocessing/image/__init__.py)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pretrained Models\n",
    "**We know that CNN's alone (with no dense layers) don't do anything other than map the presence of features from our input. This means we can use a pretrained CNN, one trained on millions of images, as the start of our model. This will allow us to have a very good convolutional base before adding our own dense layered classifier at the end.**\n"
   ],
   "id": "24f5dda3234f2375"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using a Pretrained Model\n",
   "id": "c2316fea7d672cae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "keras = tf.keras"
   ],
   "id": "a37e86b47064aebf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "### We will load the cat_vs_dogs datasets from the module tensorflow_datasets."
   ],
   "id": "ecf9000eb5a7a19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "# split the data manually into 8% training, 10% testing, 10% validation\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n"
   ],
   "id": "d0519142bb89de27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create a function object that we can use to get labels\n",
    "get_label_name = metadata.features['label'].int2str\n",
    "\n",
    "# display 2 images from the dataset\n",
    "for image, label in raw_train.take(5):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ],
   "id": "159af6f150783800"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\n",
    "### Since the size of the images are all different, we need to convert them all to the same size -- create a function."
   ],
   "id": "61fe86759815a887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "IMG_SIZE = 160  # All images will be resized to 160x160\n",
    "\n",
    "\n",
    "def format_example(image, label):\n",
    "    # returns an image that is reshaped to IMG_SIZE\n",
    "\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n"
   ],
   "id": "d309946471cbbb3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train = raw_train.map(format_example)  # apply this function to all images using map()\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)"
   ],
   "id": "8eecb7aa95d8d851"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# have a look at our images\n",
    "for image, label in train.take(2):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(get_label_name(label))"
   ],
   "id": "ed927818cbcf7ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# shuffle and batch the images\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)"
   ],
   "id": "746b92baf1a5b71a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# let's have a look at new images!!!\n",
    "for img, label in raw_train.take(2):\n",
    "    print(\"Original image shape: \", img.shape)\n",
    "for img, label in train.take(2):\n",
    "    print(\"New image shape: \", img.shape)\n",
    "    "
   ],
   "id": "5692d5b1c0d24277"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Picking a Pretrained Model",
   "id": "ad6cdccc2c26dd96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ],
   "id": "daf094ba185887d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_model.summary()",
   "id": "4109fa4c743cceb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for image, _ in train.batches.take(1):\n",
    "    pass\n",
    "\n",
    "feature_batch = base_model(image)\n",
    "print(feature_batch.shape)\n",
    "# result: (32, 5, 5, 1280)"
   ],
   "id": "1543e138eeaec4ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Freezing the Base\n",
    "### It simply means we won't make any changes to the weights of any layers that are frozen during training."
   ],
   "id": "1428dcf2e39230e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_model.trainable = False",
   "id": "bc8db4a5fb6de818"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "base_model.summary()",
   "id": "3808dbb69c13fead"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding our Classifier",
   "id": "b22319a59fcc65d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter.\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ],
   "id": "6840839906f92243"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add the prediction layer that will be a single dense neuron.\n",
    "prediction_layer = keras.layers.Dense(1)"
   ],
   "id": "1fd7ffa9c09932a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# combine these layers together in a model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_average_layer,\n",
    "    prediction_layer\n",
    "])"
   ],
   "id": "43e8293ad753a57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.summary()",
   "id": "119ae10716e3c11a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Training the Model",
   "id": "b1fdb4515d014fa8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now we will train and compile the model. We will use a very small learning rate to ensure that the model does not have any major changers made to it.",
   "id": "47248f729bb0ff14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "    loss=tf.keras.losses\n",
    "    # we use two classes\n",
    "    .BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "id": "5f11a07f8ae17ecd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# evaluate the model right now to see how it does before training it on our new images\n",
    "initial_epochs = 3\n",
    "validation_steps = 20\n",
    "loss0, acc0 = model.evaluate(validation_batches, steps=validation_steps)"
   ],
   "id": "88088126b98cfcdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# now train it on our images\n",
    "history = model.fit(train_batches, epochs=initial_epochs, validation_data=validation_batches)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "print(acc)"
   ],
   "id": "c8cc0bc5afa04561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.save(\"dogs_vs_cats.keras\")  # save the model and reload it at anytime in the future\n",
    "new_model = tf.keras.models.load_model(\"dogs_vs_cats.keras\")\n"
   ],
   "id": "201d3229322289f2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
